## hash算法
HashMap就是使用哈希表来存储的。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题，Java中HashMap采用了链地址法。链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。

基于hash算法在信息安全的应用有：
(1)    文件校验
(2)    数字签名
(3)    鉴权协议
产生哈希冲突的影响因素有：处理冲突的方法 哈希函数 装填因子

装填因子=数据总数/hash表长

## HashMap总结
### 介绍
Hashmap整体是一个哈希桶数组+Node链表或者是红黑树组成的结构，根据key的hashCode值来存储数据，大多数情况下可以直接定位得到他的值，因此具有很快的访问速度（理论是log1），但是遍历的顺序不确定。HashMap最多允许一个记录为键为null，允许多个键的值为null。非线程安全，如果需要安全可以使用同步容器Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者是使用并发容器ConcurrentHashMap。
### hashmap重要参数
```java
     int threshold;             // 所能容纳的key-value对极限 
     final float loadFactor;    // 负载因子
     int modCount;  
     int size;
```
	首先，Node[] table的初始化长度length(默认值是16)，Load factor为负载因子(默认值是0.75)，threshold是HashMap所能容纳的最大数据量的Node(键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。threshold就是在此Load factor和length(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍。而modCount字段主要用来记录HashMap内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如put新键值对，但是某个key对应的value值被覆盖不属于结构变化。

### HashMap算法确定索引位置
```java
方法一：
static final int hash(Object key) {   //jdk1.8 & jdk1.7
     int h;
     // h = key.hashCode() 为第一步 取hashCode值
     // h ^ (h >>> 16)  为第二步 高位参与运算
     return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
方法二：
static int indexFor(int h, int length) {  //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的
     return h & (length-1);  //第三步 取模运算
}

```
	原理大抵为：先取key的hashcode，然后进行高16和低16位的运算，然后再和长度进行去模运算
	JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h >>> 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。
	而h & (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h& (length-1)运算等价于对length取模，也就是h%length，但是&比%具有更高的效率。这也是为什么要使用2的n次方作为长度


### HashMap的put()流程
* put中调用putval()方法
* putval中，如果是第一次调用put，则会调用resize方法，初始化Node[]，并获取数组的长度n。
* 通过i=(n-1)&hash值，计算出下标i
* 若该位置没有值，则初始化该Node并放在这个位置即可
* 若该位有值(发生碰撞)：
	* 判断该位置的第一个数据和我们要插入的数据是否相同，若相同，则将其取出。
	* 若否，发现该节点是树结构，则调用putTreeVal方法。
	* 如碰撞之后发现是链表，则遍历列表，把节点挂在链表的表尾，若发现链表已经8位，则调用treeifyBin来将其装换为红黑树
	* 若在遍历链表中发现key值相同，则覆盖对于的node的值即可。
	* 将上面的相同节点覆盖value值
* 新增完数据，判断size是否超过阀值，进行扩容，调用resize()方法。


### HashMap中的红黑树插入时：
* 先比较两个Value有没有实现comparable接口
* 没有的话使用类名进行比较
* 如果相同则使用hashcode进行比较

HashMap中链表与红黑树的转换前提是HashMap中的节点个数超过了64个，如果没超过64的话会选择扩容而非是转换。

HashMap实现了Cloneable、Map、Serializable接口，并没有实现AbstractMap，AbstractMap是一个类而非接口

### HashMap为什么要规定初始值
扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容，避免多次调用扩容reszie()，并且扩容resize在多线程下有问题。

### resize的两代对比
1.7之前：扩容的时候使用头插，每次都会去一个个重新计算一下新的hash值位置
1.8之后：扩容的时候使用的是尾插，避免了死循环的问题，不需要再一个个去计算hash值之类的，元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此1.8不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”

## 算法：

* 学会使用一个类遍历存储值
* 使用变量保存头节点

高级结构的遍历：

* 要看到宏观的遍历（例如分圈）

```java
import java.util.ArrayList;
public class Solution {
    public static ArrayList<Integer> arr = new ArrayList();
    public ArrayList<Integer> printMatrix(int [][] matrix) {
      int tC= 0;
      int tR = 0;
      int dR = matrix.length -1 ;
      int dC = matrix[0].length - 1;
      while(tC<=dC&&tR<=dR){
          this.printEdge(matrix,tR++,tC++,dR--,dC--);
      }
       return arr;
    }
    
    public static void printEdge(int[][] m,int tR, int tC, int dR, int dC){
        if(tR==dR){
            for(int i = tC;i<dC;i++){
                arr.add(m[tR][i]);
            }
        }else if(tC==dC){
            for(int i = tR;i<dR;i++){
                arr.add(m[i][tC]);
            }
        }else{
            int curR = tR;
            int curC = tC;
            while(curC<dC){
                arr.add(m[tR][curC]);
                curC++;
            }
            while(curR!=dR){
                arr.add(m[curR][dC]);
                curR++;
            }
            while(curC!=tC){
                arr.add(m[dR][curC]);
                curC--;
            }
            while(curR!=tR){
                arr.add(m[curR][tC]);
                curR--;
            }
        }
    }
}
```

## Linux文件链接
linux中一个文件具有很多属性，uid,gid，文件大小，访问权限，文件内容block位置等。这些内容是和文件中的实际内容分开放的。文件的属性是放在叫做 i节点的结构中 ，而文件内容则放在数据块中。这个 inode(i节点) 和block（数据块）是文件系统一开始就规划好的，并且不会改变（除非你格式化）。

实体链接

在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。

删除任意一个条目，文件还是存在，只要引用数量不为 0。

有以下限制：不能跨越文件系统、不能对目录进行链接

硬链接指通过索引节点来进行连接，在Linux为文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号；
硬链接指的就是在Linux中，多个文件名指向同一索引节点；
常见用途：通过建立硬链接到重要文件，防止误删，删除其实对应的是删除其中的一个硬链接，当文件对应的硬链接都被删除了，该文件才真正被删除；

符号链接

文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式。

当源文件被删除了，链接文件就打不开了。

因为记录的是路径，所以可以为目录建立符号链接。

## List扩容
1.读取原本的长度

2.`int newCapacity = oldCapacity+(oldCapacity>>1)` 扩大1.5倍，原本无参时初始大小为10，因此若长度扩从到100的时候，需要进行从10，15，22，33，49，73，109一共6次扩充

3.newCapacity可能因为超过了int的最大值变成了负数，因此需要和minCapacity进行比较，minCapacity即为原始长度+1的数目。

## TCP拥塞控制

## Linux用于查找可执行文件的命令为：
(1)whereis

(2)locate

(3)which

(4)type

(5)find

## mysql索引

* R-Tree：空间索引

Myisam支持空间索引，可以使用geometry空间数据类型。

空间索引不会要求where子句使用索引最左前缀可以全方位索引数据，可以高效使用任何数据组合查找 配合使用mercontains()函数使用

* **全文索引**

fulltext是Myisam表特殊索引，从文本中找关键字不是直接和索引中的值进行比较。

全文索引可以和B-Tree索引混用，索引价值互不影响。

全文索引用于match against操作 而不是普通的where子句

## 死锁

* 银行家算法是避免死锁而非预防死锁
* 预防死锁的方式：限制申请方式
* 避免死锁的方式：银行家算法

* 可以通过终止和撤销进程来解除死锁
* 死锁的产生源于系统资源不足和进程推进顺序不当

* 死锁的必要条件：
	* 互斥条件
	* 请求和保持条件
	* 不可剥夺
	* 循环等待
* 死锁的原因：
	* 系统资源的竞争
	* 进程运行推进顺序不合适

## TCP
慢开始和拥塞避免：

* 发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 ...

* 注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。

* 如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。

## 计算机网络
公司门户网站随着访问用户增加需要扩展服务器数量,每台服务器在DNS配置时，域名与主机相同，为达到负载均衡，DNS服务器需要开启 启用循环

IP数据报的收发方进行跨网投递时，发送方需利用ARP协议获取 发送方本网段路由器对应端口的MAC地址

## 二八定律
网站访问数据的特点大多数呈现在"二八定律":80%的业务访问集中在20%的数据上。这时为了减轻数据的压力和提高网站的数据访问速度，则可以使用缓存机制来优化网站。

## 缓存穿透
访问一个缓存没有的数据，但是数据库也不存在，即恶意攻击。造成大量的数据打到数据库

解决方案：

1. 缓存空对象，如果缓存未命中，而数据库也没有该对象，则将这个空对象缓存起来，但有效期要设置的短一点，以免浪费空间

2.缓存预测，预测Key是否存在，如果缓存量不大可以使用hash来判断，如果量大可以使用布隆过滤器来判断。

## 缓存雪崩
缓存在同一个时间过期，请求同时打到数据库上

解决：

1.缓存过期时间加上随机值，这样大幅度减少缓存存在同一时间过期

## 解决Redis“挂掉”问题
事发前：实现Redis高可用，使用主从架构+Sentinel或Cluster，避免出现Redis挂掉的情况

事发：使用本地缓存ehcache和限流熔断(hystrix)

事发后：redis持久化，从磁盘中加载数据。

## 数据库Redis双写一致

## Cache Aside Pattern（缓存模式）
更新缓存：数据不但会写入数据库，还会写入缓存	优点：缓存不会增加一次miss，命中率高

淘汰缓存：数据只会写入数据库，不会写入缓存	优点：简单

选择更新缓存还是淘汰缓存，具体需要看更新缓存的代价，假设这个数据更新需要较大的代价，则更倾向于淘汰缓存

#### Cache Aside Pattern
读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。更新的时候，先更新数据库，然后再删除缓存。

因为在复杂的缓存场景中，缓存不只是单纯取出来的值，此时需要联合多表进行查询，因此删除缓存，而不是更新缓存，就是一个 **lazy 计算**的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。

## Redis
1、setex key 有效时间 value ----------意思就是添加并设置该键值对的存活时间
2、mset key1 value1 key2 value2 key3 value3 ....... -----------------意思就是一次性添加多个键值对
3、getset oldKey newValue -------------意思就是重新设置已存在的key的值，返回被覆盖的旧值
4、getrange key startIndex endIndex -----------意思就是获取该key对应的值的指定子字符串(起始索引从0开始)
5、mget key1 key2...... -------------意思就是一次性获取多个见对应的值
6、append key newStr ----------意思就是给已存在的字符串追加新子字符串
7、strlen key -------计算指定字符串的长度
8、expire key 10 -------意思就是设置该key的字符串的过期时间，经过10秒自动删除(过期)
9、ttl key --------查看该key的有效时长
10、ping ----------测试当前连接是否正常
11、dbsize ------------返回当前数据库中key的总数目
12、info -------查看当前连接的服务器信息和统计
13、flushdb ------------清空当前选择的数据库中所有数据
14、flushall ---------清空所有数据库中的数据。

## Linux文件搜索操作

* which [-a] comand 指令搜索
* whereis 文件搜索
* 
* 

## Linux的父子进程
在Linux上，对于多进程，子进程继承了父进程的共享内存、信号掩码、已打开的文件描述符

## asList方法

```
 public static void main(String[] args) {
        String[] a = new String[]{"1","2"};
        List list  = Arrays.asList(a);
        list.clear();
        list.add(3);
        System.out.println(list.toString());
    }
```

编译期间不会报错，在运行时报错`UnsupportedOperationException`